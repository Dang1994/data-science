{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MRC0e0KhQ0S"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWd1UlMnhT2s"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('cancer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove the ID column\n",
    "#data.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Encode the Diagnosis column (M = 1, B = 0)\n",
    "label_encoder = LabelEncoder()\n",
    "data['diagnosis'] = label_encoder.fit_transform(data['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Choose Diagnosis as the target variable\n",
    "X = data.drop(columns=['diagnosis'])  # Features\n",
    "y = data['diagnosis']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split the data into train (80%), test (15%), and validation (5%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)  # 0.25 * 20% = 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Hyperparameter Tuning for Naive Bayes\n",
    "# Define the parameter distribution for Randomized Search\n",
    "param_dist = {\n",
    "    'var_smoothing': uniform(1e-9, 1e-1)  # Smoothing parameter for variance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Naive Bayes model\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Randomized Search with Cross-Validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=nb_model,              # Base model\n",
    "    param_distributions=param_dist,  # Parameter distribution to sample from\n",
    "    n_iter=100,                      # Number of parameter settings to sample\n",
    "    scoring='accuracy',              # Evaluation metric\n",
    "    cv=10,                          # 10-fold cross-validation\n",
    "    verbose=1,                      # Print progress\n",
    "    n_jobs=-1,                      # Use all available CPU cores\n",
    "    random_state=42                 # Seed for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Randomized Search on the training data\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Accuracy:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Train the final model with the best parameters\n",
    "final_model = random_search.best_estimator_\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluate the model on the test set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "y_test_pred_prob = final_model.predict_proba(X_test)[:, 1]  # Probabilities for ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_pred_prob)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1-Score: {test_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {test_roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Predict on the unseen validation set\n",
    "y_val_pred = final_model.predict(X_val)\n",
    "y_val_pred_prob = final_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_precision = precision_score(y_val, y_val_pred)\n",
    "val_recall = recall_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "val_roc_auc = roc_auc_score(y_val, y_val_pred_prob)\n",
    "\n",
    "print(\"\\nValidation Set Performance:\")\n",
    "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall: {val_recall:.4f}\")\n",
    "print(f\"F1-Score: {val_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {val_roc_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Summary\n",
    "\n",
    "#### Hyperparameter Tuning:\n",
    "- **Best Parameters**: `{'var_smoothing': 0.037}`\n",
    "- **Best CV Accuracy**: **62.86%**\n",
    "\n",
    "#### Test Set Performance:\n",
    "- **Accuracy**: **58.82%**\n",
    "- **Precision**: **0.00%** (no positive predictions)\n",
    "- **Recall**: **0.00%**\n",
    "- **F1-Score**: **0.00%**\n",
    "- **ROC-AUC**: **56.11%**\n",
    "- **Confusion Matrix**:\n",
    "  ```\n",
    "  [[50  1]\n",
    "   [34  0]]\n",
    "  ```\n",
    "\n",
    "#### Validation Set Performance:\n",
    "- **Accuracy**: **68.97%**\n",
    "- **Precision**: **0.00%** (no positive predictions)\n",
    "- **Recall**: **0.00%**\n",
    "- **F1-Score**: **0.00%**\n",
    "- **ROC-AUC**: **61.67%**\n",
    "- **Confusion Matrix**:\n",
    "  ```\n",
    "  [[20  0]\n",
    "   [ 9  0]]\n",
    "  ```\n",
    "\n",
    "### Key Issues:\n",
    "- The model predicts **all samples as benign**, resulting in **0.00% precision, recall, and F1-score**.\n",
    "- Low accuracy and ROC-AUC indicate poor performance.\n",
    "\n",
    "### Reasons:\n",
    "- **Imbalanced Data**: The dataset may have more benign cases, causing the model to favor the majority class.\n",
    "- **Model Limitations**: Naive Bayes assumes feature independence, which may not fit this dataset well.\n",
    "\n",
    "### Next Steps:\n",
    "1. **Handle Class Imbalance**: Use oversampling, undersampling, or class weights.\n",
    "2. **Try Other Models**: Use Logistic Regression, Random Forest, or SVM.\n",
    "3. **Feature Engineering**: Explore additional features or transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "naive_bayes.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
